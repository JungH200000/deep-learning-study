# RNN의 구조와 활용 방식 알아보기

RNN의 구조를 알아보기 위해 RNN이 어떤 기능을 하게 될지에 대해 단순한 예시를 들어보겠다.

## 언어 모델

언어 모델이란 자연어의 기본적인 단위(e.g., 단어)로 이루어진 시퀀스를 확률로 표현하여 단어를 모델링하는 것이다. 쉽게 말하면 이 단어 다음에 어떤 단어가 오는 것이 적합한지 수식으로 나타낸 것이라고 보면 된다.

얌전한($w_1$) 고양이가($w_2$) 부뚜막에($w_3$) 먼저($w_4$) **\_**($w_5$)

위 문장에서 대부분의 사람들은 뒤에 올 단어에 대해서 자연스럽게 '올라간다'라고 떠올리게 된다. 이렇게 앞선 언어의 시퀀스를 바탕으로 뒤에 이어질 내용을 판단하는 언어 모델을 만들 때 RNN을 사용하는 것이 효과적이다.

RNN에 입력으로 문장의 일부분을 주고 이어질 단어를 예측할 수 있을 것이다.

글자 단위의 시퀀스를 입력 받아서 다음에 올 글자를 예측하는 RNN 모델을 구성한다고 생각해보자.

<img src="../images/rnn-hidden01.png" width=300>

$x_1$부터 $x_3$에 각각 '안', '녕', '하'라는 문자열이 입력으로 들어가는 경우를 생각해보자. 첫 번째 은닉층(hidden layer)는 첫 번째로 '안'이라는 글자가 입력되었다는 정보를 만들어내게 된다. 이 정보와 $x_2$의 입력이 두 번째 은닉층의 정보를 만들어내고, 그 정보와 $x_3$의 입력을 가지고 그 다음에 올 글자를 예측하여 $y_3$로 내보낼 수 있다. 적절한 데이터셋으로 모델을 학습시켰다면 $y_3$는 '세'라는 문자열이 나올 확률이 높다라는 정보를 출력할 것이다.

<img src="../images/rnn-hidden02.png" width=300>

그런데 만약 $x_4$로 '십'이라는 글자가 들어가면 어떤 변화가 있을까?? 안녕하세요라는 문자열 시퀀스 예측에서 안녕하십니까 문자열 시퀀스가 등장할 확률이 더 커질 것이다. 따라서 네 번째 은닉층이 앞선 문자열 시퀀스 정보와 새로운 $x_4$ 입력을 입력받아 예측한 $y_4$는 안녕하십니까를 이어나가기 위한 '니'가 될 것이다.

RNN에서는 이렇게 순서관계가 있는 입력 데이터를 바탕으로 현 시점의 은닉층 정보 $h_t$와 다음 시점의 입력 $x_{t+1}$을 통해 t+1 시점의 은닉층 정보 $h_{t+1}$을 계산하게 된다. 이런 식으로 RNN은 동일한 구조의 RNN 셀에 시퀀스 입력 데이터를 시점 순서에 따라 입력하고 출력을 계산해낼 수 있다.

## 다양한 RNN의 구조

RNN Task마다 input, output 데이터의 형태가 다를 수 있다. 각 task의 input, output이 RNN 구조에서 어떤 식으로 다르게 적용되는지 알아보자.
